##### 代码在master分支
# 总体步骤：
## 1. 数据获取——这里用python爬取前程无忧的招聘信息；
## 2. 数据处理——无效值、缺失值、重复值处理，数据结构是否一致等；
## 3. 制作可视化——做图表做可视化报告

# 具体步骤
## 1. 爬取数据
网址首页：https://www.51job.com/ 搜索关键字：数据分析
用Python爬取了约2000条的数据分析的职位信，并且将岗位名称、公司名称、工作地点、薪水、工作经历和学历最低要求 用CSV文件保存下来。
  ### 1）网站分析：
  检查源代码发现数据就在源码当中，这样就大大简化了工作。（一开始是爬取每个职位的网页链接，再去爬取每个职业网页链接的各种信息，但是这样做效率低，各种xpath容易出错，后来仔细看源码 发现可以用json直接取js对象，从而取出关键信息，加大效率）
  ### 2）细节：
  1.遍历每一页，保存到csv（虽然搜索结果有几百页，但我大概看了一下，44页以后跟数据分析就没什么关系了）
  2.数据量大，分批写入csv
  3.指定编码为utf_8_sig（否则会乱码）
 
## 2.数据处理
各个字段含义：岗位名称、公司名称、工作地点、薪水、工作经历和学历最低要求、公司类型、公司规模、公司领域
检查各个字段的含义，单位（量纲）、格式是否一致，是否有空值
  ### 1）有无缺失值
  任何一字段数据缺失超过40%~50%，删除。
  ### 2）脏数据处理
  把职业名不含数据两个字的全部删掉；删除重复数据  
  ### 3）数据转换
  统一薪水字段格式（先统一量纲，仔分成最低、最高薪水两列，再求平均）

## 3.可视化
使用数据透视表和数据透视图进行多维度（城市，学历，工作经验）的分析
